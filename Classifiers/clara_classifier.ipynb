{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import realfunctions\n",
    "import twitter\n",
    "import numpy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to make sure we are using the labels \"bot\" and \"human\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_var = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = pd.read_csv('tweets.csv')\n",
    "\n",
    "df1 = pd.DataFrame({\"Tweet\": text_data['text'], \"Status\": text_data['category']}).truncate(after=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2016 Nominees\n",
    "trump = 'realDonaldTrump'\n",
    "clinton = 'HillaryClinton'\n",
    "\n",
    "# Top 6 Prospects\n",
    "biden = 'JoeBiden'\n",
    "booker = 'CoryBooker'\n",
    "sanders = 'BernieSanders'\n",
    "\n",
    "harris = 'KamalaHarris'\n",
    "gillibrand = 'SenGillibrand'\n",
    "warren = 'elizabethforma'\n",
    "\n",
    "# DataFrames for favorites/retweets/tweets for each politician\n",
    "trump_data = twitter.tweets_favorites_retweets(trump)\n",
    "clinton_data = twitter.tweets_favorites_retweets(clinton)\n",
    "\n",
    "biden_data = twitter.tweets_favorites_retweets(biden)\n",
    "booker_data = twitter.tweets_favorites_retweets(booker)\n",
    "sanders_data = twitter.tweets_favorites_retweets(sanders)\n",
    "\n",
    "harris_data = twitter.tweets_favorites_retweets(harris)\n",
    "gillibrand_data = twitter.tweets_favorites_retweets(gillibrand)\n",
    "warren_data = twitter.tweets_favorites_retweets(warren)\n",
    "\n",
    "tweets = trump_data['tweets']\n",
    "tweets = tweets.append(clinton_data['tweets'])\n",
    "tweets = tweets.append(biden_data['tweets'])\n",
    "tweets = tweets.append(booker_data['tweets'])\n",
    "tweets = tweets.append(sanders_data['tweets'])\n",
    "tweets = tweets.append(harris_data['tweets'])\n",
    "tweets = tweets.append(gillibrand_data['tweets'])\n",
    "tweets = tweets.append(warren_data['tweets'])\n",
    "\n",
    "traits = [\"Human\"] * tweets.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame({'Tweet': tweets, 'Status': traits})\n",
    "\n",
    "all = df1.append(out)\n",
    "all = all.reset_index()\n",
    "out = out.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                 23400\n",
       "Status                                                  Bot\n",
       "Tweet     RT @The_Trump_Train: The Obama administration ...\n",
       "Name: 23400, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all = pd.DataFrame({'Tweet': all['Tweet'], 'Status': all['Status']})\n",
    "all.loc[23400]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = realfunctions.polarizeFrameNoDate(all['Tweet'])\n",
    "all = pd.concat([all, sentiments], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                     18002\n",
       "Status                                                      Bot\n",
       "Tweet         RT @brownblaze: I read an interview years ago ...\n",
       "Compound                                                -0.3182\n",
       "Negativity                                                0.103\n",
       "Neutrality                                                0.897\n",
       "Positivity                                                    0\n",
       "Tweet         RT @brownblaze: I read an interview years ago ...\n",
       "Name: 18002, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all.loc[18002]\n",
    "#sentiments.loc[20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bot' 'Human']\n",
      "Class label =  Bot\n",
      "['tweet' 'numwords' 'pos' 'neg' 'neut' 'comp']\n",
      "[16040, 12, 0.426, 0.001, 0.576, 0.5729]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "feats = pd.DataFrame({'Features': ['tweet', 'numwords', 'pos', 'neg', 'neut', 'comp']})\n",
    "# Organize our data\n",
    "label_names = all['Status'].unique()\n",
    "labels = all['Status'].values\n",
    "feature_names = feats['Features'].values\n",
    "alltweets = all['Tweet'].values\n",
    "toFloat = []\n",
    "words = []\n",
    "posit = all['Positivity'].values\n",
    "negat = all['Negativity'].values\n",
    "neutr = all['Neutrality'].values\n",
    "compo = all['Compound'].values\n",
    "for i in range(len(alltweets)):\n",
    "    toFloat.append(str(alltweets[i]))\n",
    "    words.append(len(str(alltweets[i]).split()))\n",
    "    \n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(toFloat)\n",
    "toFloat = le.transform(toFloat)\n",
    "\n",
    "features = []\n",
    "for i in range(len(words)):\n",
    "    features.append([toFloat[i], words[i], posit[i]+0.001, negat[i]+0.001, neutr[i]+0.001, \n",
    "                     compo[i]+0.001])\n",
    "\n",
    "    \n",
    "# Look at our data\n",
    "print(label_names)\n",
    "print('Class label = ', labels[3])\n",
    "print(feature_names)\n",
    "print(features[0])\n",
    "\n",
    "# Split our data\n",
    "train, test, train_labels, test_labels = train_test_split(features,\n",
    "                                                          labels,\n",
    "                                                          test_size=0.25,\n",
    "                                                          random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This checks to see if the file has been run once\n",
    "\n",
    "#pickle will help save the classifier state after the classifier has been trained\n",
    "#pickling is important, as it allows python object hierarchies to turn into bitstreams\n",
    "\n",
    "#If the file has not been run, run the code below\n",
    "if run_var == 0:\n",
    "    classifier = BernoulliNB()\n",
    "    model = classifier.fit(train, train_labels)\n",
    "    classify_buffer = open('russian_bots_bernoulli_bayes.pickle', 'wb')\n",
    "    pickle.dump(model, classify_buffer)\n",
    "    classify_buffer.close()\n",
    "    run_var += 1\n",
    "    \n",
    "\n",
    "#The alternative is re-opneing the classifier_buffer and updating the classifier    \n",
    "else:\n",
    "    classify_buffer = open('russian_bots_bernoulli_bayes.pickle', 'rb')\n",
    "    try: \n",
    "        classifier = pickle.load(classify_buffer)\n",
    "    except EOFError:\n",
    "        classify_buffer.close()\n",
    "        run_var += 1\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bot' 'Bot' 'Bot' ... 'Bot' 'Bot' 'Bot']\n",
      "17154\n",
      "0\n",
      "0.7218141541331468\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "preds = classifier.predict(test)\n",
    "print(preds)\n",
    "print(len(preds))\n",
    "counter = 0\n",
    "for i in range(len(preds)):\n",
    "    if preds[i] == 'Human':\n",
    "        counter += 1\n",
    "\n",
    "print(counter)\n",
    "# Evaluate accuracy\n",
    "print(accuracy_score(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(run_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
